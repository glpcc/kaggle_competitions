{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model.model1 import Net\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Training dataset\n",
    "df = pd.read_csv('data/cleaned_train.csv')\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide between train and test data\n",
    "train = df[:800]\n",
    "test = df[800:]\n",
    "# Divide between x,y \n",
    "train_x = torch.tensor(train.iloc[:,3:].values).float()\n",
    "train_y = torch.tensor(train.iloc[:,2].values).float()\n",
    "test_x = torch.tensor(test.iloc[:,3:].values).float()\n",
    "test_y = torch.tensor(test.iloc[:,2].values).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the network\n",
    "net = Net(inputs=17,outputs=1,dropout_prob=0)\n",
    "# Move all to gpu\n",
    "if torch.cuda.is_available():\n",
    "   net = net.to(\"cuda:0\")\n",
    "   train_x = train_x.to(\"cuda:0\")\n",
    "   train_y = train_y.to(\"cuda:0\")\n",
    "   test_x = test_x.to(\"cuda:0\")\n",
    "   test_y = test_y.to(\"cuda:0\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the network for training\n",
    "epochs = 200\n",
    "batch_size = 10\n",
    "# Initialize loss function\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "# Initialize optimizer\n",
    "optm = torch.optim.Adam(params=net.parameters(),lr=1e-2)\n",
    "scheduler1 = torch.optim.lr_scheduler.LinearLR(optm,1,0.1,epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide tensors into batch sizes\n",
    "train_x = train_x.split(batch_size);\n",
    "train_y = train_y.split(batch_size);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0, Loss: 0.4581195116043091, Accuracy: 0.791208803653717\n",
      "EPOCH: 1, Loss: 0.42024660110473633, Accuracy: 0.8461538553237915\n",
      "EPOCH: 2, Loss: 0.4115566313266754, Accuracy: 0.8241758346557617\n",
      "EPOCH: 3, Loss: 0.4055011570453644, Accuracy: 0.8351648449897766\n",
      "EPOCH: 4, Loss: 0.39766091108322144, Accuracy: 0.8351648449897766\n",
      "EPOCH: 5, Loss: 0.3914257287979126, Accuracy: 0.8461538553237915\n",
      "EPOCH: 6, Loss: 0.3918834328651428, Accuracy: 0.8681318759918213\n",
      "EPOCH: 7, Loss: 0.4081686735153198, Accuracy: 0.8241758346557617\n",
      "EPOCH: 8, Loss: 0.38242626190185547, Accuracy: 0.8351648449897766\n",
      "EPOCH: 9, Loss: 0.37289994955062866, Accuracy: 0.8351648449897766\n",
      "EPOCH: 10, Loss: 0.35680291056632996, Accuracy: 0.8461538553237915\n",
      "EPOCH: 11, Loss: 0.35749825835227966, Accuracy: 0.8351648449897766\n",
      "EPOCH: 12, Loss: 0.3691140115261078, Accuracy: 0.8351648449897766\n",
      "EPOCH: 13, Loss: 0.3724166750907898, Accuracy: 0.8571428656578064\n",
      "EPOCH: 14, Loss: 0.3726233243942261, Accuracy: 0.8351648449897766\n",
      "EPOCH: 15, Loss: 0.34033718705177307, Accuracy: 0.8681318759918213\n",
      "EPOCH: 16, Loss: 0.3345569372177124, Accuracy: 0.8681318759918213\n",
      "EPOCH: 17, Loss: 0.35167551040649414, Accuracy: 0.8351648449897766\n",
      "EPOCH: 18, Loss: 0.33858758211135864, Accuracy: 0.8571428656578064\n",
      "EPOCH: 19, Loss: 0.3412935435771942, Accuracy: 0.8461538553237915\n",
      "EPOCH: 20, Loss: 0.3522987961769104, Accuracy: 0.8681318759918213\n",
      "EPOCH: 21, Loss: 0.37250879406929016, Accuracy: 0.8681318759918213\n",
      "EPOCH: 22, Loss: 0.34195905923843384, Accuracy: 0.8571428656578064\n",
      "EPOCH: 23, Loss: 0.34911948442459106, Accuracy: 0.8461538553237915\n",
      "EPOCH: 24, Loss: 0.31078624725341797, Accuracy: 0.8791208863258362\n",
      "EPOCH: 25, Loss: 0.33847641944885254, Accuracy: 0.8791208863258362\n",
      "EPOCH: 26, Loss: 0.33301687240600586, Accuracy: 0.8791208863258362\n",
      "EPOCH: 27, Loss: 0.32721710205078125, Accuracy: 0.8681318759918213\n",
      "EPOCH: 28, Loss: 0.3100214898586273, Accuracy: 0.8791208863258362\n",
      "EPOCH: 29, Loss: 0.33290398120880127, Accuracy: 0.8791208863258362\n",
      "EPOCH: 30, Loss: 0.32879236340522766, Accuracy: 0.8571428656578064\n",
      "EPOCH: 31, Loss: 0.3308974802494049, Accuracy: 0.8681318759918213\n",
      "EPOCH: 32, Loss: 0.3267459273338318, Accuracy: 0.8571428656578064\n",
      "EPOCH: 33, Loss: 0.33850330114364624, Accuracy: 0.8681318759918213\n",
      "EPOCH: 34, Loss: 0.33713892102241516, Accuracy: 0.8681318759918213\n",
      "EPOCH: 35, Loss: 0.3347742259502411, Accuracy: 0.8571428656578064\n",
      "EPOCH: 36, Loss: 0.3317137062549591, Accuracy: 0.901098906993866\n",
      "EPOCH: 37, Loss: 0.347609281539917, Accuracy: 0.8351648449897766\n",
      "EPOCH: 38, Loss: 0.33515241742134094, Accuracy: 0.8461538553237915\n",
      "EPOCH: 39, Loss: 0.34800100326538086, Accuracy: 0.8901098966598511\n",
      "EPOCH: 40, Loss: 0.3347322344779968, Accuracy: 0.8571428656578064\n",
      "EPOCH: 41, Loss: 0.3302043676376343, Accuracy: 0.8791208863258362\n",
      "EPOCH: 42, Loss: 0.31692588329315186, Accuracy: 0.8901098966598511\n",
      "EPOCH: 43, Loss: 0.3518644869327545, Accuracy: 0.8461538553237915\n",
      "EPOCH: 44, Loss: 0.3502657115459442, Accuracy: 0.8571428656578064\n",
      "EPOCH: 45, Loss: 0.3254164457321167, Accuracy: 0.8681318759918213\n",
      "EPOCH: 46, Loss: 0.34314262866973877, Accuracy: 0.8681318759918213\n",
      "EPOCH: 47, Loss: 0.32219135761260986, Accuracy: 0.8791208863258362\n",
      "EPOCH: 48, Loss: 0.3281634747982025, Accuracy: 0.8571428656578064\n",
      "EPOCH: 49, Loss: 0.3511454164981842, Accuracy: 0.8681318759918213\n",
      "EPOCH: 50, Loss: 0.34135299921035767, Accuracy: 0.8571428656578064\n",
      "EPOCH: 51, Loss: 0.32499757409095764, Accuracy: 0.8681318759918213\n",
      "EPOCH: 52, Loss: 0.31061747670173645, Accuracy: 0.8791208863258362\n",
      "EPOCH: 53, Loss: 0.3511809706687927, Accuracy: 0.8681318759918213\n",
      "EPOCH: 54, Loss: 0.3334029018878937, Accuracy: 0.8681318759918213\n",
      "EPOCH: 55, Loss: 0.34732288122177124, Accuracy: 0.8901098966598511\n",
      "EPOCH: 56, Loss: 0.3164972960948944, Accuracy: 0.8681318759918213\n",
      "EPOCH: 57, Loss: 0.32682502269744873, Accuracy: 0.8791208863258362\n",
      "EPOCH: 58, Loss: 0.3207385241985321, Accuracy: 0.8791208863258362\n",
      "EPOCH: 59, Loss: 0.33279335498809814, Accuracy: 0.8571428656578064\n",
      "EPOCH: 60, Loss: 0.31639161705970764, Accuracy: 0.8901098966598511\n",
      "EPOCH: 61, Loss: 0.3272809088230133, Accuracy: 0.8681318759918213\n",
      "EPOCH: 62, Loss: 0.33487093448638916, Accuracy: 0.8461538553237915\n",
      "EPOCH: 63, Loss: 0.3189845383167267, Accuracy: 0.8901098966598511\n",
      "EPOCH: 64, Loss: 0.34940317273139954, Accuracy: 0.8681318759918213\n",
      "EPOCH: 65, Loss: 0.32913878560066223, Accuracy: 0.901098906993866\n",
      "EPOCH: 66, Loss: 0.31477490067481995, Accuracy: 0.8791208863258362\n",
      "EPOCH: 67, Loss: 0.34475699067115784, Accuracy: 0.8681318759918213\n",
      "EPOCH: 68, Loss: 0.30959078669548035, Accuracy: 0.8791208863258362\n",
      "EPOCH: 69, Loss: 0.31675440073013306, Accuracy: 0.8791208863258362\n",
      "EPOCH: 70, Loss: 0.30424964427948, Accuracy: 0.8681318759918213\n",
      "EPOCH: 71, Loss: 0.3199039697647095, Accuracy: 0.8681318759918213\n",
      "EPOCH: 72, Loss: 0.3334544897079468, Accuracy: 0.8791208863258362\n",
      "EPOCH: 73, Loss: 0.33039578795433044, Accuracy: 0.8681318759918213\n",
      "EPOCH: 74, Loss: 0.3511306941509247, Accuracy: 0.8681318759918213\n",
      "EPOCH: 75, Loss: 0.35015326738357544, Accuracy: 0.8681318759918213\n",
      "EPOCH: 76, Loss: 0.3269306421279907, Accuracy: 0.8681318759918213\n",
      "EPOCH: 77, Loss: 0.31036633253097534, Accuracy: 0.8791208863258362\n",
      "EPOCH: 78, Loss: 0.3452169895172119, Accuracy: 0.8791208863258362\n",
      "EPOCH: 79, Loss: 0.32832348346710205, Accuracy: 0.8681318759918213\n",
      "EPOCH: 80, Loss: 0.31240588426589966, Accuracy: 0.8571428656578064\n",
      "EPOCH: 81, Loss: 0.3092525601387024, Accuracy: 0.8681318759918213\n",
      "EPOCH: 82, Loss: 0.32592546939849854, Accuracy: 0.8791208863258362\n",
      "EPOCH: 83, Loss: 0.31577059626579285, Accuracy: 0.8681318759918213\n",
      "EPOCH: 84, Loss: 0.3245271146297455, Accuracy: 0.8791208863258362\n",
      "EPOCH: 85, Loss: 0.3385159373283386, Accuracy: 0.8681318759918213\n",
      "EPOCH: 86, Loss: 0.339148610830307, Accuracy: 0.8681318759918213\n",
      "EPOCH: 87, Loss: 0.33369073271751404, Accuracy: 0.8681318759918213\n",
      "EPOCH: 88, Loss: 0.3208674490451813, Accuracy: 0.8681318759918213\n",
      "EPOCH: 89, Loss: 0.3274482190608978, Accuracy: 0.8791208863258362\n",
      "EPOCH: 90, Loss: 0.33434295654296875, Accuracy: 0.8681318759918213\n",
      "EPOCH: 91, Loss: 0.3519099950790405, Accuracy: 0.8681318759918213\n",
      "EPOCH: 92, Loss: 0.34228721261024475, Accuracy: 0.8571428656578064\n",
      "EPOCH: 93, Loss: 0.3334318697452545, Accuracy: 0.8571428656578064\n",
      "EPOCH: 94, Loss: 0.3452172577381134, Accuracy: 0.8681318759918213\n",
      "EPOCH: 95, Loss: 0.34416869282722473, Accuracy: 0.8571428656578064\n",
      "EPOCH: 96, Loss: 0.31984245777130127, Accuracy: 0.8681318759918213\n",
      "EPOCH: 97, Loss: 0.3120364844799042, Accuracy: 0.8791208863258362\n",
      "EPOCH: 98, Loss: 0.317985862493515, Accuracy: 0.8791208863258362\n",
      "EPOCH: 99, Loss: 0.3212305009365082, Accuracy: 0.8571428656578064\n",
      "EPOCH: 100, Loss: 0.3185041844844818, Accuracy: 0.8791208863258362\n",
      "EPOCH: 101, Loss: 0.3204288184642792, Accuracy: 0.8791208863258362\n",
      "EPOCH: 102, Loss: 0.3285113275051117, Accuracy: 0.8571428656578064\n",
      "EPOCH: 103, Loss: 0.33322155475616455, Accuracy: 0.8461538553237915\n",
      "EPOCH: 104, Loss: 0.3187188506126404, Accuracy: 0.8571428656578064\n",
      "EPOCH: 105, Loss: 0.33697834610939026, Accuracy: 0.8681318759918213\n",
      "EPOCH: 106, Loss: 0.3260082006454468, Accuracy: 0.8791208863258362\n",
      "EPOCH: 107, Loss: 0.30848854780197144, Accuracy: 0.8791208863258362\n",
      "EPOCH: 108, Loss: 0.3150850832462311, Accuracy: 0.8901098966598511\n",
      "EPOCH: 109, Loss: 0.3287600576877594, Accuracy: 0.8681318759918213\n",
      "EPOCH: 110, Loss: 0.3202328085899353, Accuracy: 0.8571428656578064\n",
      "EPOCH: 111, Loss: 0.31681597232818604, Accuracy: 0.8791208863258362\n",
      "EPOCH: 112, Loss: 0.3084293603897095, Accuracy: 0.8901098966598511\n",
      "EPOCH: 113, Loss: 0.2973349094390869, Accuracy: 0.8791208863258362\n",
      "EPOCH: 114, Loss: 0.3074953854084015, Accuracy: 0.8681318759918213\n",
      "EPOCH: 115, Loss: 0.33289480209350586, Accuracy: 0.8681318759918213\n",
      "EPOCH: 116, Loss: 0.3271110951900482, Accuracy: 0.8681318759918213\n",
      "EPOCH: 117, Loss: 0.32000088691711426, Accuracy: 0.8791208863258362\n",
      "EPOCH: 118, Loss: 0.32981371879577637, Accuracy: 0.8681318759918213\n",
      "EPOCH: 119, Loss: 0.32869336009025574, Accuracy: 0.8681318759918213\n",
      "EPOCH: 120, Loss: 0.31574007868766785, Accuracy: 0.8681318759918213\n",
      "EPOCH: 121, Loss: 0.30681031942367554, Accuracy: 0.8681318759918213\n",
      "EPOCH: 122, Loss: 0.3130169212818146, Accuracy: 0.8681318759918213\n",
      "EPOCH: 123, Loss: 0.3131749629974365, Accuracy: 0.8791208863258362\n",
      "EPOCH: 124, Loss: 0.30654454231262207, Accuracy: 0.8791208863258362\n",
      "EPOCH: 125, Loss: 0.3139860928058624, Accuracy: 0.8681318759918213\n",
      "EPOCH: 126, Loss: 0.3004271388053894, Accuracy: 0.8571428656578064\n",
      "EPOCH: 127, Loss: 0.29904016852378845, Accuracy: 0.8681318759918213\n",
      "EPOCH: 128, Loss: 0.3196996748447418, Accuracy: 0.8901098966598511\n",
      "EPOCH: 129, Loss: 0.312181293964386, Accuracy: 0.8901098966598511\n",
      "EPOCH: 130, Loss: 0.3212023079395294, Accuracy: 0.8681318759918213\n",
      "EPOCH: 131, Loss: 0.306938499212265, Accuracy: 0.8901098966598511\n",
      "EPOCH: 132, Loss: 0.3137962520122528, Accuracy: 0.8791208863258362\n",
      "EPOCH: 133, Loss: 0.3183409571647644, Accuracy: 0.8791208863258362\n",
      "EPOCH: 134, Loss: 0.31293147802352905, Accuracy: 0.8681318759918213\n",
      "EPOCH: 135, Loss: 0.3020479679107666, Accuracy: 0.8791208863258362\n",
      "EPOCH: 136, Loss: 0.3046324551105499, Accuracy: 0.901098906993866\n",
      "EPOCH: 137, Loss: 0.3028448522090912, Accuracy: 0.8901098966598511\n",
      "EPOCH: 138, Loss: 0.30425289273262024, Accuracy: 0.8681318759918213\n",
      "EPOCH: 139, Loss: 0.2932929992675781, Accuracy: 0.8901098966598511\n",
      "EPOCH: 140, Loss: 0.30122196674346924, Accuracy: 0.8901098966598511\n",
      "EPOCH: 141, Loss: 0.31825658679008484, Accuracy: 0.8901098966598511\n",
      "EPOCH: 142, Loss: 0.2987206280231476, Accuracy: 0.8901098966598511\n",
      "EPOCH: 143, Loss: 0.3105047047138214, Accuracy: 0.8681318759918213\n",
      "EPOCH: 144, Loss: 0.30412912368774414, Accuracy: 0.8791208863258362\n",
      "EPOCH: 145, Loss: 0.3047071099281311, Accuracy: 0.8681318759918213\n",
      "EPOCH: 146, Loss: 0.301596999168396, Accuracy: 0.8791208863258362\n",
      "EPOCH: 147, Loss: 0.3090081810951233, Accuracy: 0.8791208863258362\n",
      "EPOCH: 148, Loss: 0.30623993277549744, Accuracy: 0.8681318759918213\n",
      "EPOCH: 149, Loss: 0.2972835302352905, Accuracy: 0.901098906993866\n",
      "EPOCH: 150, Loss: 0.30006173253059387, Accuracy: 0.8901098966598511\n",
      "EPOCH: 151, Loss: 0.3035004436969757, Accuracy: 0.8901098966598511\n",
      "EPOCH: 152, Loss: 0.29462820291519165, Accuracy: 0.901098906993866\n",
      "EPOCH: 153, Loss: 0.297637939453125, Accuracy: 0.8901098966598511\n",
      "EPOCH: 154, Loss: 0.30810949206352234, Accuracy: 0.8791208863258362\n",
      "EPOCH: 155, Loss: 0.3045121729373932, Accuracy: 0.8791208863258362\n",
      "EPOCH: 156, Loss: 0.3033398687839508, Accuracy: 0.8681318759918213\n",
      "EPOCH: 157, Loss: 0.3072766661643982, Accuracy: 0.8791208863258362\n",
      "EPOCH: 158, Loss: 0.30408114194869995, Accuracy: 0.8571428656578064\n",
      "EPOCH: 159, Loss: 0.3029004633426666, Accuracy: 0.8901098966598511\n",
      "EPOCH: 160, Loss: 0.3131627142429352, Accuracy: 0.8681318759918213\n",
      "EPOCH: 161, Loss: 0.31708964705467224, Accuracy: 0.8791208863258362\n",
      "EPOCH: 162, Loss: 0.31850579380989075, Accuracy: 0.8681318759918213\n",
      "EPOCH: 163, Loss: 0.31693628430366516, Accuracy: 0.8571428656578064\n",
      "EPOCH: 164, Loss: 0.3196197748184204, Accuracy: 0.8681318759918213\n",
      "EPOCH: 165, Loss: 0.3077382743358612, Accuracy: 0.901098906993866\n",
      "EPOCH: 166, Loss: 0.3177555203437805, Accuracy: 0.901098906993866\n",
      "EPOCH: 167, Loss: 0.30346429347991943, Accuracy: 0.8681318759918213\n",
      "EPOCH: 168, Loss: 0.30624979734420776, Accuracy: 0.8791208863258362\n",
      "EPOCH: 169, Loss: 0.304605633020401, Accuracy: 0.8571428656578064\n",
      "EPOCH: 170, Loss: 0.30544760823249817, Accuracy: 0.8791208863258362\n",
      "EPOCH: 171, Loss: 0.3073447644710541, Accuracy: 0.8901098966598511\n",
      "EPOCH: 172, Loss: 0.30699586868286133, Accuracy: 0.8791208863258362\n",
      "EPOCH: 173, Loss: 0.31105032563209534, Accuracy: 0.8791208863258362\n",
      "EPOCH: 174, Loss: 0.32151737809181213, Accuracy: 0.8681318759918213\n",
      "EPOCH: 175, Loss: 0.3144187927246094, Accuracy: 0.8791208863258362\n",
      "EPOCH: 176, Loss: 0.3162846863269806, Accuracy: 0.8681318759918213\n",
      "EPOCH: 177, Loss: 0.31589266657829285, Accuracy: 0.8681318759918213\n",
      "EPOCH: 178, Loss: 0.32574495673179626, Accuracy: 0.8571428656578064\n",
      "EPOCH: 179, Loss: 0.3196920156478882, Accuracy: 0.8791208863258362\n",
      "EPOCH: 180, Loss: 0.30521318316459656, Accuracy: 0.8571428656578064\n",
      "EPOCH: 181, Loss: 0.3033197820186615, Accuracy: 0.8681318759918213\n",
      "EPOCH: 182, Loss: 0.3012174665927887, Accuracy: 0.8791208863258362\n",
      "EPOCH: 183, Loss: 0.3022695481777191, Accuracy: 0.8791208863258362\n",
      "EPOCH: 184, Loss: 0.31638965010643005, Accuracy: 0.8681318759918213\n",
      "EPOCH: 185, Loss: 0.30627623200416565, Accuracy: 0.8791208863258362\n",
      "EPOCH: 186, Loss: 0.3012098968029022, Accuracy: 0.8901098966598511\n",
      "EPOCH: 187, Loss: 0.30543529987335205, Accuracy: 0.8901098966598511\n",
      "EPOCH: 188, Loss: 0.30239665508270264, Accuracy: 0.8681318759918213\n",
      "EPOCH: 189, Loss: 0.308218777179718, Accuracy: 0.8791208863258362\n",
      "EPOCH: 190, Loss: 0.30408307909965515, Accuracy: 0.8681318759918213\n",
      "EPOCH: 191, Loss: 0.30667877197265625, Accuracy: 0.8681318759918213\n",
      "EPOCH: 192, Loss: 0.30806323885917664, Accuracy: 0.8791208863258362\n",
      "EPOCH: 193, Loss: 0.30139538645744324, Accuracy: 0.8681318759918213\n",
      "EPOCH: 194, Loss: 0.3067973256111145, Accuracy: 0.8681318759918213\n",
      "EPOCH: 195, Loss: 0.3081265687942505, Accuracy: 0.8681318759918213\n",
      "EPOCH: 196, Loss: 0.31084132194519043, Accuracy: 0.8791208863258362\n",
      "EPOCH: 197, Loss: 0.3075495958328247, Accuracy: 0.8791208863258362\n",
      "EPOCH: 198, Loss: 0.31493619084358215, Accuracy: 0.8681318759918213\n",
      "EPOCH: 199, Loss: 0.3034899830818176, Accuracy: 0.8791208863258362\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "accuracies = []\n",
    "num_batches = 50\n",
    "test_y = test_y.reshape((test_y.shape[0],1))\n",
    "max_accuracy = 0\n",
    "best_model = copy.deepcopy(net.state_dict())\n",
    "for epoch in range(epochs):\n",
    "    net.train()\n",
    "    for i in range(num_batches):\n",
    "        indx = random.randint(0,len(train_x)-1)\n",
    "        x = train_x[indx]\n",
    "        y = train_y[indx]\n",
    "        net_out = net.forward(x,x.size()[0])\n",
    "        #print(all(i == net_out[0] for i in net_out))\n",
    "        loss = loss_fn.forward(net_out,y.reshape(y.size()[0],1))\n",
    "        optm.zero_grad()\n",
    "        loss.backward()\n",
    "        optm.step()\n",
    "    scheduler1.step()\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        net_out = net.forward(test_x,test_x.size()[0])\n",
    "        loss = loss_fn.forward(net_out,test_y.reshape(test_y.size()[0],1))\n",
    "        predictions = net_out.round()\n",
    "        accuracy = 1- (predictions - test_y).abs().sum()/test_y.size()[0]\n",
    "        if accuracy > max_accuracy:\n",
    "            best_model = copy.deepcopy(net.state_dict())\n",
    "            max_accuracy = accuracy\n",
    "        losses.append(loss)\n",
    "        accuracies.append(accuracies)\n",
    "        print(f'EPOCH: {epoch}, Loss: {loss}, Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model,'saved_models/best_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
